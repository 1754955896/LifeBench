import json
import os.path
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed

from event.phone_data_gen import *

def run_communication_task(date, contact, file_path, initial_data):
    """æ‰§è¡Œé€šè®¯æ•°æ®ç”Ÿæˆä»»åŠ¡"""
    g1 = CommunicationOperationGenerator()
    return g1.phone_gen_callandmsm(date, contact, file_path, initial_data)


def run_notecalendar_task(date, contact, file_path, initial_data):
    """æ‰§è¡Œç¬”è®°æ—¥å†æ•°æ®ç”Ÿæˆä»»åŠ¡"""
    g2 = NoteCalendarOperationGenerator(random_seed=42)
    return g2.phone_gen_noteandcalendar(date, contact, file_path, initial_data)


def run_gallery_task(date, contact, file_path, initial_data):
    """æ‰§è¡Œç›¸å†Œæ•°æ®ç”Ÿæˆä»»åŠ¡"""
    g3 = GalleryOperationGenerator(random_seed=42)
    return g3.phone_gen_gallery(date, contact, file_path, initial_data)


def run_push_task(date, contact, file_path, initial_data):
    """æ‰§è¡Œæ¨é€æ•°æ®ç”Ÿæˆä»»åŠ¡"""
    g4 = PushOperationGenerator(random_seed=42)
    return g4.phone_gen_push(date, contact, file_path, initial_data)


def run_fitness_health_task(date, contact, file_path, initial_data):
    """æ‰§è¡Œè¿åŠ¨å¥åº·æ•°æ®ç”Ÿæˆä»»åŠ¡"""
    g5 = FitnessHealthOperationGenerator(random_seed=42)
    return g5.phone_gen_fitness_health(date, contact, file_path, initial_data)


def run_chat_task(date, contact, file_path, initial_data):
    """æ‰§è¡ŒèŠå¤©æ•°æ®ç”Ÿæˆä»»åŠ¡"""
    g6 = ChatOperationGenerator(random_seed=42)
    return g6.phone_gen_agent_chat(date, contact, file_path, initial_data)


def run_perception_task(date, contact, file_path, initial_data):
    """æ‰§è¡Œæ„ŸçŸ¥æ•°æ®ç”Ÿæˆä»»åŠ¡"""
    g7 = PerceptionDataGenerator()
    return g7.generate_perception_data(date,initial_data)


# å•ä¸ªæ—¥æœŸçš„å®Œæ•´å¤„ç†ä»»åŠ¡
def process_single_date(date, contact, file_path, initial_a, initial_b, initial_c, initial_d, initial_e, initial_f, initial_g):
    """
    å¤„ç†å•ä¸ªæ—¥æœŸçš„æ‰€æœ‰æ•°æ®ç”Ÿæˆï¼ˆä¸è¿›è¡Œæ–‡ä»¶å†™å…¥ï¼‰
    :param date: è¦å¤„ç†çš„æ—¥æœŸ
    :param contact: è”ç³»äººä¿¡æ¯
    :param file_path: æ–‡ä»¶ä¿å­˜è·¯å¾„
    :param initial_a: communicationæ“ä½œçš„åˆå§‹æ•°æ®
    :param initial_b: note&calendaræ“ä½œçš„åˆå§‹æ•°æ®
    :param initial_c: galleryæ“ä½œçš„åˆå§‹æ•°æ®
    :param initial_d: pushæ“ä½œçš„åˆå§‹æ•°æ®
    :param initial_e: fitness_healthæ“ä½œçš„åˆå§‹æ•°æ®
    :param initial_f: chatæ“ä½œçš„åˆå§‹æ•°æ®
    :param initial_g: perceptionæ“ä½œçš„åˆå§‹æ•°æ®
    :return: å¤„ç†ç»“æœï¼ˆæˆåŠŸ/å¤±è´¥ï¼Œæ—¥æœŸï¼Œç”Ÿæˆçš„æ•°æ®å­—å…¸ï¼‰
    """
    try:
        # å†…éƒ¨å¹¶è¡Œæ‰§è¡Œ7ä¸ªç”Ÿæˆå™¨ä»»åŠ¡
        with ThreadPoolExecutor(max_workers=7) as inner_executor:
            # æäº¤æ‰€æœ‰å†…éƒ¨ä»»åŠ¡
            future_a = inner_executor.submit(run_communication_task, date, contact, file_path, initial_a)
            future_b = inner_executor.submit(run_notecalendar_task, date, contact, file_path, initial_b)
            future_c = inner_executor.submit(run_gallery_task, date, contact, file_path, initial_c)
            future_d = inner_executor.submit(run_push_task, date, contact, file_path, initial_d)
            future_e = inner_executor.submit(run_fitness_health_task, date, contact, file_path, initial_e)
            future_f = inner_executor.submit(run_chat_task, date, contact, file_path, initial_f)
            future_g = inner_executor.submit(run_perception_task, date, contact, file_path, initial_g)

            # è·å–æ‰§è¡Œç»“æœ
            a_result = future_a.result()
            b_result = future_b.result()
            c_result = future_c.result()
            d_result = future_d.result()
            e_result = future_e.result()
            f_result = future_f.result()
            g_result = future_g.result()

        # æ•´ç†ç”Ÿæˆçš„æ•°æ®
        generated_data = {
            "event_note.json": b_result,
            "event_call.json": a_result,
            "event_gallery.json": c_result,
            "event_push.json": d_result,
            "event_fitness_health.json": e_result,
            "event_chat.json": f_result,
            "event_perception.json": g_result
        }

        print(f"æˆåŠŸå¤„ç†æ—¥æœŸï¼š{date}")
        return (True, date, generated_data)

    except Exception as e:
        print(f"å¤„ç†æ—¥æœŸ {date} æ—¶å‡ºé”™ï¼š{str(e)}")
        import traceback
        traceback.print_exc()
        return (False, date, None)


# ä¸»å‡½æ•°ï¼šå¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†æ‰€æœ‰æ—¥æœŸ
def process_phone_data(file_path):
    """
    å¤„ç†æ‰‹æœºæ•°æ®çš„åå¤„ç†æ“ä½œï¼šåˆ†ç±»ã€æ’åºã€æ·»åŠ phone_id
    :param file_path: æ•°æ®æ–‡ä»¶è·¯å¾„
    """
    # æ•°æ®åå¤„ç†ï¼šåˆ†ç±»ã€æ’åºã€æ·»åŠ phone_id
    print(f"\nå¼€å§‹æ•°æ®åå¤„ç†...")
    
    # 1. å®šä¹‰éœ€è¦å¤„ç†çš„æ–‡ä»¶ï¼ˆé™¤äº†contact.jsonå’Œevent_perception.jsonï¼‰
    phone_data_dir = os.path.join(file_path, "phone_data")
    
    # ç›´æ¥åˆ é™¤event_perception.jsonæ–‡ä»¶
    event_perception_file = os.path.join(phone_data_dir, "event_perception.json")
    if os.path.exists(event_perception_file):
        os.remove(event_perception_file)
        print(f"å·²åˆ é™¤event_perception.jsonæ–‡ä»¶: {event_perception_file}")
    
    files_to_process = [f for f in os.listdir(phone_data_dir) if f.endswith('.json') and f.startswith('event_')]
    
    # 2. åˆ›å»ºprocessæ–‡ä»¶å¤¹
    process_dir = os.path.join(file_path, "process")
    process_dir = os.path.join(process_dir,"phone_data")
    os.makedirs(process_dir, exist_ok=True)
    
    # 3. å¤„ç†æ¯ä¸ªæ–‡ä»¶
    for filename in files_to_process:
        file_path_old = os.path.join(phone_data_dir, filename)
        
        # è¯»å–åŸå§‹æ•°æ®
        with open(file_path_old, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # æŒ‰typeåˆ†ç±»
        type_dict = {}
        for item in data:
            if 'type' in item:
                data_type = item['type']
                if data_type not in type_dict:
                    type_dict[data_type] = []
                type_dict[data_type].append(item)
            else:
                # å¦‚æœæ²¡æœ‰typeå­—æ®µï¼Œä½¿ç”¨æ–‡ä»¶åä½œä¸ºç±»å‹
                data_type = filename.replace('event_', '').replace('.json', '')
                if data_type not in type_dict:
                    type_dict[data_type] = []
                type_dict[data_type].append(item)
        
        # ç”Ÿæˆæ–°æ–‡ä»¶å¹¶æ’åº
        for data_type, type_data in type_dict.items():
            # æ’åº
            if data_type in ['call', 'gallery', 'note', 'calendar', 'push','photo','sms']:
                # ä½¿ç”¨datetimeå­—æ®µæ’åº
                sorted_data = sorted(type_data, key=lambda x: x.get('datetime', ''))
            elif data_type == 'perception':
                # å…ˆæŒ‰dateæ’åºï¼Œå†æŒ‰timeæ•°ç»„çš„ç¬¬ä¸€ä¸ªå…ƒç´ æ’åº
                sorted_data = sorted(type_data, key=lambda x: (x.get('date', ''), x.get('time', [''])[0]))
            elif data_type == 'fitness_health':
                # æŒ‰æ—¥æœŸå­—æ®µæ’åº
                sorted_data = sorted(type_data, key=lambda x: x.get('æ—¥æœŸ', ''))
            elif data_type == 'agent_chat':
                # æŒ‰dateå­—æ®µæ’åº
                sorted_data = sorted(type_data, key=lambda x: x.get('date', ''))
            else:
                # é»˜è®¤æŒ‰datetimeæ’åº
                sorted_data = sorted(type_data, key=lambda x: x.get('datetime', ''))
            
            # æ·»åŠ phone_id
            for i, item in enumerate(sorted_data):
                item['phone_id'] = i
            
            # ä¿å­˜æ–°æ–‡ä»¶
            new_filename = f"{data_type}.json"
            new_file_path = os.path.join(phone_data_dir, new_filename)
            with open(new_file_path, 'w', encoding='utf-8') as f:
                json.dump(sorted_data, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… ç”Ÿæˆæ–°æ–‡ä»¶ï¼š{new_filename}ï¼Œå…± {len(sorted_data)} æ¡è®°å½•")
        
        # å°†è€æ–‡ä»¶ç§»åŠ¨åˆ°processæ–‡ä»¶å¤¹
        new_file_path_old = os.path.join(process_dir, filename)
        os.replace(file_path_old, new_file_path_old)
        print(f"ğŸ“ å·²å°†åŸæ–‡ä»¶ {filename} ç§»åŠ¨åˆ° process æ–‡ä»¶å¤¹")
    
    print(f"\næ•°æ®åå¤„ç†å®Œæˆï¼")


def parallel_process_dates(start_time, end_time, contact, file_path, initial_a, initial_b, initial_c, initial_d, initial_e, initial_f, initial_g,
                           max_workers=8):
    """
    å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†æ‰€æœ‰æ—¥æœŸ
    :param start_time: å¼€å§‹æ—¶é—´
    :param end_time: ç»“æŸæ—¶é—´
    :param contact: è”ç³»äººä¿¡æ¯
    :param file_path: æ–‡ä»¶ä¿å­˜è·¯å¾„
    :param initial_a: communicationæ“ä½œçš„åˆå§‹æ•°æ®
    :param initial_b: note&calendaræ“ä½œçš„åˆå§‹æ•°æ®
    :param initial_c: galleryæ“ä½œçš„åˆå§‹æ•°æ®
    :param initial_d: pushæ“ä½œçš„åˆå§‹æ•°æ®
    :param initial_e: fitness_healthæ“ä½œçš„åˆå§‹æ•°æ®
    :param initial_f: chatæ“ä½œçš„åˆå§‹æ•°æ®
    :param initial_g: perceptionæ“ä½œçš„åˆå§‹æ•°æ®
    :param max_workers: æœ€å¤§å¹¶è¡Œçº¿ç¨‹æ•°
    :return: å¤„ç†ç»Ÿè®¡ç»“æœ
    """
    # æ”¶é›†æ‰€æœ‰å¤„ç†ç»“æœ
    success_dates = []
    failed_dates = []
    
    # æ”¶é›†æ‰€æœ‰ç”Ÿæˆçš„æ•°æ®
    data_collector = {
        "event_note.json": [],
        "event_call.json": [],
        "event_gallery.json": [],
        "event_push.json": [],
        "event_fitness_health.json": [],
        "event_chat.json": [],
        "event_perception.json": []
    }

    # åˆ›å»ºçº¿ç¨‹æ± ï¼Œå¹¶è¡Œå¤„ç†æ‰€æœ‰æ—¥æœŸ
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰æ—¥æœŸçš„å¤„ç†ä»»åŠ¡
        futures = []
        for date in iterate_dates(start_time, end_time):
            future = executor.submit(
                process_single_date,
                date=date,
                contact=contact,
                file_path=file_path,
                initial_a=initial_a,
                initial_b=initial_b,
                initial_c=initial_c,
                initial_d=initial_d,
                initial_e=initial_e,
                initial_f=initial_f,
                initial_g=initial_g
            )
            futures.append(future)

        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆå¹¶æ”¶é›†ç»“æœ
        for future in as_completed(futures):
            success, date, generated_data = future.result()
            if success:
                success_dates.append(date)
                # åˆå¹¶ç”Ÿæˆçš„æ•°æ®åˆ°æ”¶é›†å™¨
                for filename, data in generated_data.items():
                    if isinstance(data, list) and isinstance(data_collector[filename], list):
                        data_collector[filename].extend(data)
                    else:
                        data_collector[filename] = data
            else:
                failed_dates.append(date)

    # åˆ›å»ºphone_dataæ–‡ä»¶å¤¹ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    phone_data_dir = os.path.join(file_path, "phone_data")
    os.makedirs(phone_data_dir, exist_ok=True)
    
    # å°†æ‰€æœ‰æ”¶é›†çš„æ•°æ®å†™å…¥æ–‡ä»¶ï¼ˆå¢é‡å¼ï¼Œä¿ç•™åŸæœ‰æ•°æ®ï¼‰
    for filename, data in data_collector.items():
        file_path = os.path.join(phone_data_dir, filename)
        try:
            # è¯»å–åŸæœ‰æ•°æ®
            existing_data = []
            if os.path.exists(file_path):
                with open(file_path, "r", encoding="utf-8") as f:
                    file_content = f.read().strip()
                    if file_content:
                        existing_data = json.loads(file_content)
                    else:
                        existing_data = []
            
            # åˆå¹¶æ•°æ®
            if isinstance(data, list) and isinstance(existing_data, list):
                # å¦‚æœéƒ½æ˜¯åˆ—è¡¨ï¼Œåˆå¹¶åˆ—è¡¨
                merged_data = existing_data + data
            else:
                # å¦åˆ™ï¼Œä½¿ç”¨æ–°æ•°æ®
                merged_data = data
            
            # å†™å…¥åˆå¹¶åçš„æ•°æ®
            with open(file_path, "w", encoding="utf-8") as f:
                json.dump(merged_data, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… æ•°æ®æˆåŠŸå†™å…¥æ–‡ä»¶ï¼š{filename}")
            print(f"   å…±å†™å…¥ {len(merged_data)} æ¡æ•°æ®")
        except json.JSONDecodeError as e:
            print(f"âŒ æ–‡ä»¶ {filename} JSONæ ¼å¼é”™è¯¯ï¼Œå°†è¦†ç›–åŸæœ‰æ–‡ä»¶ï¼š{str(e)}")
            # å¦‚æœJSONæ ¼å¼é”™è¯¯ï¼Œä½¿ç”¨æ–°æ•°æ®è¦†ç›–
            with open(file_path, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âŒ å†™å…¥æ–‡ä»¶ {filename} æ—¶å‡ºé”™ï¼š{str(e)}")

    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    total_dates = len(success_dates) + len(failed_dates)
    print(f"\nå¤„ç†å®Œæˆç»Ÿè®¡ï¼š")
    print(f"æ€»æ—¥æœŸæ•°ï¼š{total_dates}")
    print(f"æˆåŠŸå¤„ç†ï¼š{len(success_dates)} ä¸ª")
    print(f"å¤„ç†å¤±è´¥ï¼š{len(failed_dates)} ä¸ª")
    if failed_dates:
        print(f"å¤±è´¥æ—¥æœŸï¼š{failed_dates}")

    return {
        "total": total_dates,
        "success": len(success_dates),
        "failed": len(failed_dates),
        "failed_dates": failed_dates
    }


def parallel_process_perception_only(start_time, end_time, contact, file_path, initial_g, max_workers=8):
    """
    å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†æ‰€æœ‰æ—¥æœŸçš„æ„ŸçŸ¥æ•°æ®ç”Ÿæˆï¼ˆä»…è¿è¡Œæ„ŸçŸ¥æ•°æ®ä»»åŠ¡ï¼‰
    :param start_time: å¼€å§‹æ—¶é—´
    :param end_time: ç»“æŸæ—¶é—´
    :param contact: è”ç³»äººä¿¡æ¯
    :param file_path: æ–‡ä»¶ä¿å­˜è·¯å¾„
    :param initial_g: perceptionæ“ä½œçš„åˆå§‹æ•°æ®
    :param max_workers: æœ€å¤§å¹¶è¡Œçº¿ç¨‹æ•°
    :return: å¤„ç†ç»Ÿè®¡ç»“æœ
    """
    # æ”¶é›†æ‰€æœ‰å¤„ç†ç»“æœ
    success_dates = []
    failed_dates = []
    
    # æ”¶é›†æ‰€æœ‰ç”Ÿæˆçš„æ„ŸçŸ¥æ•°æ®
    all_perception_data = []
    
    # åˆ›å»ºphone_dataæ–‡ä»¶å¤¹ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    phone_data_dir = os.path.join(file_path, "phone_data")
    os.makedirs(phone_data_dir, exist_ok=True)
    
    # å•ä¸ªæ„ŸçŸ¥ä»»åŠ¡å¤„ç†å‡½æ•°
    def process_perception_date(date):
        try:
            # è¿è¡Œæ„ŸçŸ¥æ•°æ®ç”Ÿæˆä»»åŠ¡
            result = run_perception_task(date, contact, file_path, initial_g)
            
            print(f"æˆåŠŸç”Ÿæˆæ„ŸçŸ¥æ•°æ®ï¼š{date}")
            return (True, date, result)
        except Exception as e:
            print(f"ç”Ÿæˆæ„ŸçŸ¥æ•°æ® {date} æ—¶å‡ºé”™ï¼š{str(e)}")
            return (False, date, None)
    
    # åˆ›å»ºçº¿ç¨‹æ± ï¼Œå¹¶è¡Œå¤„ç†æ‰€æœ‰æ—¥æœŸ
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰æ—¥æœŸçš„å¤„ç†ä»»åŠ¡
        futures = []
        for date in iterate_dates(start_time, end_time):
            future = executor.submit(process_perception_date, date)
            futures.append(future)
    
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆå¹¶æ”¶é›†ç»“æœ
        for future in as_completed(futures):
            success, date, result = future.result()
            if success and result is not None:
                success_dates.append(date)
                # æ”¶é›†ç”Ÿæˆçš„æ•°æ®
                if isinstance(result, list):
                    all_perception_data.extend(result)
                else:
                    all_perception_data.append(result)
            else:
                failed_dates.append(date)
    
    # å¢é‡å¼å†™å…¥æ–‡ä»¶ï¼ˆä¿ç•™åŸæœ‰æ•°æ®ï¼‰
    perception_file_path = os.path.join(phone_data_dir, "event_perception.json")
    try:
        # è¯»å–åŸæœ‰æ•°æ®
        existing_data = []
        if os.path.exists(perception_file_path):
            with open(perception_file_path, "r", encoding="utf-8") as f:
                file_content = f.read().strip()
                if file_content:
                    existing_data = json.loads(file_content)
                else:
                    existing_data = []
        
        # åˆå¹¶æ•°æ®
        if isinstance(all_perception_data, list) and isinstance(existing_data, list):
            # å¦‚æœéƒ½æ˜¯åˆ—è¡¨ï¼Œåˆå¹¶åˆ—è¡¨
            merged_data = existing_data + all_perception_data
        else:
            # å¦åˆ™ï¼Œä½¿ç”¨æ–°æ•°æ®
            merged_data = all_perception_data
        
        # å†™å…¥åˆå¹¶åçš„æ•°æ®
        with open(perception_file_path, "w", encoding="utf-8") as f:
            json.dump(merged_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… æ„ŸçŸ¥æ•°æ®æˆåŠŸå†™å…¥æ–‡ä»¶ï¼š{perception_file_path}")
        print(f"   å…±å†™å…¥ {len(merged_data)} æ¡æ•°æ®")
    except json.JSONDecodeError as e:
        print(f"âŒ JSONæ ¼å¼é”™è¯¯ï¼Œå°†è¦†ç›–åŸæœ‰æ–‡ä»¶ï¼š{str(e)}")
        # å¦‚æœJSONæ ¼å¼é”™è¯¯ï¼Œä½¿ç”¨æ–°æ•°æ®è¦†ç›–
        with open(perception_file_path, "w", encoding="utf-8") as f:
            json.dump(all_perception_data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"âŒ å†™å…¥æ„ŸçŸ¥æ•°æ®æ–‡ä»¶æ—¶å‡ºé”™ï¼š{str(e)}")
    
    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    total_dates = len(success_dates) + len(failed_dates)
    print(f"\næ„ŸçŸ¥æ•°æ®å¤„ç†å®Œæˆç»Ÿè®¡ï¼š")
    print(f"æ€»æ—¥æœŸæ•°ï¼š{total_dates}")
    print(f"æˆåŠŸå¤„ç†ï¼š{len(success_dates)} ä¸ª")
    print(f"å¤„ç†å¤±è´¥ï¼š{len(failed_dates)} ä¸ª")
    if failed_dates:
        print(f"å¤±è´¥æ—¥æœŸï¼š{failed_dates}")
    
    return {
        "total": total_dates,
        "success": len(success_dates),
        "failed": len(failed_dates),
        "failed_dates": failed_dates
    }


if __name__ == "__main__":
    import argparse
    
    # å‘½ä»¤è¡Œå‚æ•°è§£æ
    parser = argparse.ArgumentParser(description='æ‰‹æœºæ“ä½œç”Ÿæˆæ¨¡å—')
    parser.add_argument('--file-path', type=str, default='output/xujing/', help='æ•°æ®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--start-time', type=str, default='2025-01-01', help='å¼€å§‹æ—¥æœŸ')
    parser.add_argument('--end-time', type=str, default='2025-12-31', help='ç»“æŸæ—¥æœŸ')
    parser.add_argument('--max-workers', type=int, default=40, help='æœ€å¤§å¹¶è¡Œçº¿ç¨‹æ•°')
    parser.add_argument('--process-only', action='store_true', help='ä»…æ‰§è¡Œæ•°æ®åå¤„ç†æ“ä½œï¼Œä¸ç”Ÿæˆæ–°æ•°æ®')
    args = parser.parse_args()

    file_path = args.file_path
    start_time = args.start_time
    end_time = args.end_time
    persona = read_json_file(file_path + 'persona.json')

    contact = {}
    if os.path.exists(file_path + "phone_data/contact.json"):
        contact = read_json_file(file_path + "phone_data/contact.json")
    else:
        contact = contact_gen(persona)
        contact = remove_json_wrapper(contact, json_type='array')
        contact = json.loads(contact)
        # åˆ›å»ºphone_dataæ–‡ä»¶å¤¹ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        phone_data_dir = os.path.join(file_path, "phone_data")
        os.makedirs(phone_data_dir, exist_ok=True)
        with open(os.path.join(phone_data_dir, "contact.json"), "w", encoding="utf-8") as f:
            json.dump(contact, f, ensure_ascii=False, indent=2)

    a = []
    b = []
    c = []
    d = []
    e = []
    f = []
    g = []
    if os.path.exists(file_path + "phone_data/event_gallery.json"):
        a = read_json_file(file_path + "phone_data/event_gallery.json")
    if os.path.exists(file_path + "phone_data/event_push.json"):
        b = read_json_file(file_path + "phone_data/event_push.json")
    if os.path.exists(file_path + "phone_data/event_call.json"):
        c = read_json_file(file_path + "phone_data/event_call.json")
    if os.path.exists(file_path + "phone_data/event_note.json"):
        d = read_json_file(file_path + "phone_data/event_note.json")
    if os.path.exists(file_path + "phone_data/event_fitness_health.json"):
        e = read_json_file(file_path + "phone_data/event_fitness_health.json")
    if os.path.exists(file_path + "phone_data/event_chat.json"):
        f = read_json_file(file_path + "phone_data/event_chat.json")
    if os.path.exists(file_path + "phone_data/event_perception.json"):
        g = read_json_file(file_path + "phone_data/event_perception.json")
    extool.load_from_json(read_json_file(file_path + 'daily_event.json'), persona,read_json_file(file_path + 'daily_draft.json'))
    # for i in iterate_dates(start_time,end_time):
    #     phone_gen(i,contact,file_path,a,b,c,d,e)
    #
    # for i in iterate_dates(start_time,end_time):
    #
    #     g1 = CommunicationOperationGenerator()
    #     a = g1.phone_gen_callandmsm(i,contact,file_path,a)
    #     #
    #     # g2 = NoteCalendarOperationGenerator(random_seed=42)
    #     # # ç”Ÿæˆ2023-10-05çš„æ—¥å†å’Œç¬”è®°æ•°æ®ï¼ˆæ€»æ•°â‰¤4ï¼‰
    #     # b = g2.phone_gen_noteandcalendar(i,contact,file_path,b)
    #     #
    #     # g3 = GalleryOperationGenerator(random_seed=42)
    #     # c = g3.phone_gen_gallery(i,contact,file_path,c)
    #     #
    #     # g4 = PushOperationGenerator(random_seed=42)
    #     # d = g4.phone_gen_push(i,contact,file_path,d)
    #     print('---------------------------')
    #     print(a)
    #     print('---------------------------')
    #     print(b)
    #     print('---------------------------')
    #     print(c)
    #     print('---------------------------')
    #     print(d)
    #     with open(file_path + "phone_data/event_note.json", "w", encoding="utf-8") as f:
    #         json.dump(d, f, ensure_ascii=False, indent=2)
    #     with open(file_path + "phone_data/event_call.json", "w", encoding="utf-8") as f:
    #         json.dump(c, f, ensure_ascii=False, indent=2)
    #     with open(file_path + "phone_data/event_gallery.json", "w", encoding="utf-8") as f:
    #         json.dump(a, f, ensure_ascii=False, indent=2)
    #     with open(file_path + "phone_data/event_push.json", "w", encoding="utf-8") as f:
    #         json.dump(b, f, ensure_ascii=False, indent=2)
    # å•ä¸ªç”Ÿæˆå™¨ä»»åŠ¡çš„å°è£…ï¼ˆç”¨äºå†…éƒ¨å¹¶è¡Œï¼‰


    # æ ¹æ®å‚æ•°å†³å®šæ‰§è¡Œæ¨¡å¼
    if args.process_only:
        print(f"ä»…æ‰§è¡Œæ•°æ®åå¤„ç†æ“ä½œ...")
        # ç›´æ¥æ‰§è¡Œæ•°æ®åå¤„ç†
        process_phone_data(file_path)
    else:
        # æ‰§è¡Œå…¨éƒ¨æ•°æ®ç”Ÿæˆä»»åŠ¡
        print(f"å¼€å§‹ç”Ÿæˆæ‰€æœ‰ç±»å‹çš„æ‰‹æœºæ•°æ®ï¼Œæ—¥æœŸèŒƒå›´ï¼š{start_time} åˆ° {end_time}")
        result = parallel_process_dates(
            start_time=start_time,
            end_time=end_time,
            contact=contact,
            file_path=file_path,
            initial_a=a,
            initial_b=b,
            initial_c=c,
            initial_d=d,
            initial_e=e,
            initial_f=f,
            initial_g=g,
            max_workers=args.max_workers  # å¯æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
        )
        
        # æ‰§è¡Œæ•°æ®åå¤„ç†æ“ä½œ
        process_phone_data(file_path)